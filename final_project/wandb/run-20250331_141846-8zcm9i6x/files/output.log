Loaded 283003 train examples from data/quora-train.csv
Loaded 40429 train examples from data/quora-dev.csv
Applied LoRA to GPT-2 model
Trainable parameters: 589,824 (0.47% of total)
C:\Users\Abcom\miniconda3\envs\cs224n_dfp\lib\site-packages\torch\amp\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
Total parameters: 125,621,762
Trainable parameters: 591,362 (0.47%)
train-0:   0%|                                                                             | 0/35376 [00:00<?, ?it/s]C:\Users\Abcom\miniconda3\envs\cs224n_dfp\lib\site-packages\torch\amp\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
train-0:   0%|                                                                  | 9/35376 [00:18<19:55:19,  2.03s/it]
Traceback (most recent call last):
  File "paraphrase_detection.py", line 344, in <module>
    train(args)
  File "paraphrase_detection.py", line 201, in train
    scaler.scale(loss).backward()
  File "C:\Users\Abcom\miniconda3\envs\cs224n_dfp\lib\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\Abcom\miniconda3\envs\cs224n_dfp\lib\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\Abcom\miniconda3\envs\cs224n_dfp\lib\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
